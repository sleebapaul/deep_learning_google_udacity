{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get the data from the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to download: notMNIST_large.tar.gz\n",
      "0%....5%....10%....15%....20%....25%....30%....35%....40%....45%....50%....55%....60%....65%....70%....75%....80%....85%....90%....95%....100%\n",
      "Download Complete!\n",
      "Found and verified /Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large.tar.gz\n",
      "Attempting to download: notMNIST_small.tar.gz\n",
      "0%....5%....10%....15%....20%....25%....30%....35%....40%....45%....50%....55%....60%....65%....70%....75%....80%....85%....90%....95%....100%\n",
      "Download Complete!\n",
      "Found and verified /Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small.tar.gz\n"
     ]
    }
   ],
   "source": [
    "url = 'https://commondatastorage.googleapis.com/books1000/'\n",
    "last_percent_reported = None\n",
    "data_root = '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/' # Change me to store data elsewhere\n",
    "\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  dest_filename = os.path.join(data_root, filename)\n",
    "  if force or not os.path.exists(dest_filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(dest_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', dest_filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
    "  return dest_filename\n",
    "\n",
    "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)\n",
    "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data for /Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large. This may take a while. Please wait.\n",
      "['/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/A', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/B', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/C', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/D', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/E', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/F', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/G', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/H', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/I', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/J']\n",
      "Extracting data for /Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small. This may take a while. Please wait.\n",
      "['/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/A', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/B', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/C', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/D', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/E', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/F', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/G', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/H', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/I', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/J']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(data_root)\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "\n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying a sample picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABtklEQVR4nGWSMWuUQRCGn9ndS0LU\nkIPDKAZEIY1YaRUQggpBQREhB4IYFGysUudXaKFYaZE0BlELQRCRWAiWWgWbQzSFCRExUSHefbuv\nxX53+S6Zct95n5mdGajGWPPx+hLG3hi/9XxDSX+P4nYpnttKUio6ukMoH7tJhqNTyLxxkbjHOSVJ\nUtLWkW7VHed5CgCLB6bxfUZjYEWFJKnQs10deS4odbk/D5XcMkfMsL2RIbF+ro9rNNbUuqmS+6SP\nG5iVFodWFSUlrTUyN6dErsGb7WUEWBybqlgdJ37rx2GuKGbuQkX0zEtL0PimKClqtV6Zvn2UZhlk\nMf+10OVev54z0uY4Q8x0xUcV8b60gDNGv5Tc1ggGASzWL8HE3eFk7RoGuHR88rWL2dhUUeThFbGc\nw8OS63lRzrwXUZ/3YRguHfs0wvJmEFjn5IQMSO7sOx/BMyd9HcWAwHV1MvceAczZB+kpgyGEMMCp\ntpKkqJVhHIGrausBtVz+4Hrea9QNajD9XYVapzEw9s+XO0/61YT3SUlSelnDM7eVeh0nvUUx1/hT\np8Yr/dsRo0Jy+RQiQKrch1n6D9XsNf4mz2OCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/A/Q2hlbHRlbmhhbS1VbHRyYUNvbmQub3Rm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling the test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_folders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-15fed85a5d34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdataset_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtrain_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_folders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mtest_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_folders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_folders' is not defined"
     ]
    }
   ],
   "source": [
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "  \"\"\"Load the data for a single letter label.\"\"\"\n",
    "  image_files = os.listdir(folder)\n",
    "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "  print(folder)\n",
    "  num_images = 0\n",
    "  for image in image_files:\n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "      image_data = (ndimage.imread(image_file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      num_images = num_images + 1\n",
    "    except IOError as e:\n",
    "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  return dataset\n",
    "        \n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "  dataset_names = []\n",
    "  for folder in data_folders:\n",
    "    set_filename = folder + '.pickle'\n",
    "    dataset_names.append(set_filename)\n",
    "    if os.path.exists(set_filename) and not force:\n",
    "      # You may override by setting force=True.\n",
    "      print('%s already present - Skipping pickling.' % set_filename)\n",
    "    else:\n",
    "      print('Pickling %s.' % set_filename)\n",
    "      dataset = load_letter(folder, min_num_images_per_class)\n",
    "      try:\n",
    "        with open(set_filename, 'wb') as f:\n",
    "          pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "      except Exception as e:\n",
    "        print('Unable to save data to', set_filename, ':', e)\n",
    "  \n",
    "  return dataset_names\n",
    "\n",
    "train_datasets = maybe_pickle(train_folders, 45000)\n",
    "test_datasets = maybe_pickle(test_folders, 1800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the pickle saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/A.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1872, 28, 28)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This pickle contains 1872 elements\n",
    "- Each element is an image\n",
    "- Each image is 28 x 28 pixels\n",
    "- Each element of pickle is an numpy array with 28 rows and 28 elements in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.45294118, -0.45686275, -0.49607843, -0.5       , -0.46470588,\n",
       "        -0.48039216, -0.5       , -0.49607843, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.44117647, -0.40980393, -0.17843138, -0.04509804, -0.26078433,\n",
       "        -0.1509804 , -0.35882354, -0.5       , -0.49607843, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.49215686, -0.5       ,\n",
       "        -0.2254902 ,  0.11960784,  0.26862746,  0.5       ,  0.37058824,\n",
       "         0.38627452, -0.01372549, -0.37843138, -0.49215686, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.49215686, -0.5       , -0.32745099,\n",
       "         0.06862745,  0.30000001,  0.5       ,  0.48039216,  0.49215686,\n",
       "         0.5       ,  0.39411765,  0.04509804, -0.5       , -0.49607843,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.49215686, -0.5       , -0.31960785,\n",
       "         0.03333334,  0.44509804,  0.49607843,  0.49607843,  0.49215686,\n",
       "         0.49607843,  0.46078432,  0.13137256, -0.3392157 , -0.48823529,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.48039216, -0.5       , -0.17058824,\n",
       "         0.49607843,  0.49607843,  0.49607843,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.44117647,  0.4137255 ,  0.00588235, -0.5       ,\n",
       "        -0.5       , -0.49607843, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.49215686, -0.5       , -0.20196079,  0.20980392,\n",
       "         0.40588236,  0.48823529,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.49607843,  0.5       ,  0.45686275,  0.01764706, -0.37843138,\n",
       "        -0.5       , -0.49607843, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.48823529, -0.5       ,  0.00980392,  0.20588236,\n",
       "         0.45686275,  0.5       ,  0.48823529,  0.48823529,  0.5       ,\n",
       "         0.49215686,  0.5       ,  0.35882354,  0.36666667, -0.26862746,\n",
       "        -0.5       , -0.48823529, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.48431373, -0.45294118,  0.04117647,  0.36666667,\n",
       "         0.5       ,  0.49607843,  0.49215686,  0.47254902,  0.4254902 ,\n",
       "         0.49215686,  0.49607843,  0.5       ,  0.42156863, -0.06078431,\n",
       "        -0.5       , -0.49215686, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49607843, -0.5       , -0.31568629,  0.23333333,  0.5       ,\n",
       "         0.49215686,  0.5       ,  0.45294118,  0.21764706,  0.23333333,\n",
       "         0.30000001,  0.5       ,  0.49215686,  0.49607843,  0.06862745,\n",
       "        -0.22941177, -0.5       , -0.49607843, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.49607843, -0.5       ,\n",
       "        -0.44901961, -0.37450981,  0.17058824,  0.31176472,  0.5       ,\n",
       "         0.49215686,  0.5       ,  0.2764706 , -0.43333334, -0.10392157,\n",
       "         0.22156863,  0.44901961,  0.5       ,  0.5       ,  0.37843138,\n",
       "         0.04901961, -0.34705883, -0.5       , -0.49215686, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.49607843, -0.5       ,\n",
       "        -0.36666667, -0.46078432,  0.04117647,  0.5       ,  0.48431373,\n",
       "         0.49607843,  0.49215686,  0.0254902 , -0.49215686, -0.23333333,\n",
       "         0.1627451 ,  0.46078432,  0.5       ,  0.5       ,  0.46862745,\n",
       "         0.10784314, -0.22941177, -0.5       , -0.49215686, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.48823529,\n",
       "        -0.43333334, -0.1509804 ,  0.4254902 ,  0.44901961,  0.5       ,\n",
       "         0.5       ,  0.33137256, -0.06078431, -0.42156863, -0.48431373,\n",
       "        -0.09607843,  0.24509804,  0.37450981,  0.5       ,  0.5       ,\n",
       "         0.37450981, -0.20196079, -0.44117647, -0.5       , -0.49607843,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.48823529,\n",
       "        -0.41764706,  0.18627451,  0.48823529,  0.49215686,  0.49607843,\n",
       "         0.42941177,  0.0882353 , -0.28823531, -0.5       , -0.49215686,\n",
       "        -0.36274511,  0.1509804 ,  0.45686275,  0.49607843,  0.5       ,\n",
       "         0.41764706,  0.05294118, -0.26862746, -0.5       , -0.49607843,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.49607843, -0.5       ,\n",
       "        -0.19803922,  0.40588236,  0.5       ,  0.5       ,  0.49607843,\n",
       "         0.36274511,  0.0372549 , -0.3509804 , -0.5       , -0.46862745,\n",
       "        -0.37450981, -0.10784314,  0.47254902,  0.49215686,  0.49215686,\n",
       "         0.5       ,  0.15490197, -0.37843138, -0.40196079, -0.48431373,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.38627452,\n",
       "        -0.21372549,  0.24117647,  0.5       ,  0.5       ,  0.42941177,\n",
       "         0.21764706, -0.19019608, -0.5       , -0.49215686, -0.5       ,\n",
       "        -0.44509804, -0.17058824,  0.12352941,  0.5       ,  0.49215686,\n",
       "         0.48823529,  0.5       , -0.14705883, -0.44117647, -0.46470588,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.49607843, -0.48823529, -0.33137256,\n",
       "         0.17450981,  0.46470588,  0.49607843,  0.5       ,  0.46470588,\n",
       "         0.29215688,  0.06078431, -0.11960784, -0.26078433, -0.04509804,\n",
       "        -0.17450981, -0.12745099,  0.38235295,  0.42941177,  0.49215686,\n",
       "         0.5       ,  0.47647059,  0.22941177, -0.3509804 , -0.48431373,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.49607843, -0.5       , -0.42156863, -0.1627451 ,\n",
       "         0.35882354,  0.49607843,  0.5       ,  0.5       ,  0.47254902,\n",
       "         0.44117647,  0.30784315,  0.24117647,  0.42941177,  0.18627451,\n",
       "         0.28823531,  0.35882354,  0.4254902 ,  0.45294118,  0.49607843,\n",
       "         0.5       ,  0.48039216,  0.43333334, -0.21372549, -0.4254902 ,\n",
       "        -0.5       , -0.49607843, -0.5       ],\n",
       "       [-0.5       , -0.48823529, -0.48823529, -0.31568629,  0.10392157,\n",
       "         0.42156863,  0.5       ,  0.49607843,  0.49607843,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.49607843,  0.46078432,\n",
       "         0.49215686,  0.47647059,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.48823529,  0.5       ,  0.16666667, -0.36666667,\n",
       "        -0.48431373, -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.48431373, -0.48431373, -0.07254902,  0.38627452,\n",
       "         0.39411765,  0.5       ,  0.49215686,  0.5       ,  0.49607843,\n",
       "         0.47647059,  0.48823529,  0.5       ,  0.49215686,  0.49607843,\n",
       "         0.49215686,  0.5       ,  0.5       ,  0.49215686,  0.49215686,\n",
       "         0.5       ,  0.48823529,  0.5       ,  0.33137256, -0.33137256,\n",
       "        -0.45294118, -0.5       , -0.5       ],\n",
       "       [-0.49607843, -0.5       , -0.43333334, -0.00196078,  0.47254902,\n",
       "         0.45686275,  0.5       ,  0.5       ,  0.48431373,  0.48039216,\n",
       "         0.48039216,  0.48431373,  0.4137255 ,  0.49215686,  0.40980393,\n",
       "         0.44901961,  0.38627452,  0.46862745,  0.48823529,  0.5       ,\n",
       "         0.49607843,  0.49607843,  0.5       ,  0.36666667, -0.16666667,\n",
       "        -0.4137255 , -0.5       , -0.49607843],\n",
       "       [-0.5       , -0.47254902, -0.14313726,  0.21764706,  0.47647059,\n",
       "         0.5       ,  0.49607843,  0.47647059,  0.06470589, -0.03333334,\n",
       "         0.26862746, -0.04509804, -0.17058824, -0.10392157, -0.17058824,\n",
       "         0.06470589,  0.1       , -0.19803922, -0.02156863,  0.31176472,\n",
       "         0.46470588,  0.45294118,  0.5       ,  0.49607843,  0.26078433,\n",
       "        -0.36274511, -0.5       , -0.49215686],\n",
       "       [-0.48431373, -0.33529413, -0.04901961,  0.33137256,  0.5       ,\n",
       "         0.48431373,  0.5       ,  0.13529412, -0.21372549, -0.36274511,\n",
       "        -0.5       , -0.46078432, -0.44509804, -0.5       , -0.43725491,\n",
       "        -0.47647059, -0.36666667, -0.4254902 , -0.47647059, -0.01764706,\n",
       "         0.23333333,  0.38235295,  0.5       ,  0.49215686,  0.31960785,\n",
       "         0.15490197, -0.5       , -0.49607843],\n",
       "       [-0.44901961, -0.30784315,  0.09607843,  0.48039216,  0.49607843,\n",
       "         0.5       ,  0.43333334,  0.00980392, -0.29215688, -0.47254902,\n",
       "        -0.5       , -0.49215686, -0.49607843, -0.48431373, -0.49607843,\n",
       "        -0.49607843, -0.5       , -0.49215686, -0.5       , -0.43725491,\n",
       "         0.02156863,  0.44509804,  0.5       ,  0.5       ,  0.4254902 ,\n",
       "         0.07254902, -0.11960784, -0.48431373],\n",
       "       [-0.39803922, -0.12745099,  0.3509804 ,  0.5       ,  0.48823529,\n",
       "         0.43725491,  0.19019608, -0.11176471, -0.43725491, -0.5       ,\n",
       "        -0.49607843, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.49607843, -0.49607843, -0.48823529, -0.5       ,\n",
       "        -0.25686276,  0.39803922,  0.42156863,  0.49607843,  0.48039216,\n",
       "         0.36274511,  0.00588235, -0.5       ],\n",
       "       [-0.33137256,  0.21764706,  0.48431373,  0.5       ,  0.4254902 ,\n",
       "         0.44117647, -0.02156863, -0.40980393, -0.44509804, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.49607843, -0.5       ,\n",
       "        -0.41764706,  0.1627451 ,  0.44901961,  0.45294118,  0.5       ,\n",
       "         0.5       , -0.00980392, -0.34313726],\n",
       "       [-0.33137256, -0.02941176, -0.00588235,  0.08431373,  0.33137256,\n",
       "         0.02156863, -0.40980393, -0.49215686, -0.49215686, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.49607843, -0.5       ,\n",
       "        -0.35490197, -0.2372549 ,  0.19803922,  0.29607844,  0.01372549,\n",
       "         0.20196079, -0.17843138, -0.45294118],\n",
       "       [-0.48431373, -0.40196079, -0.37450981, -0.48039216, -0.45294118,\n",
       "        -0.46470588, -0.49607843, -0.49607843, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.46470588, -0.4254902 , -0.48431373, -0.38235295, -0.45686275,\n",
       "        -0.46862745, -0.19803922, -0.44901961]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of 0th row of zeroth pickle: 28\n",
      "Length of 1th row of zeroth pickle: 28\n",
      "Length of 2th row of zeroth pickle: 28\n",
      "Length of 3th row of zeroth pickle: 28\n",
      "Length of 4th row of zeroth pickle: 28\n",
      "Length of 5th row of zeroth pickle: 28\n",
      "Length of 6th row of zeroth pickle: 28\n",
      "Length of 7th row of zeroth pickle: 28\n",
      "Length of 8th row of zeroth pickle: 28\n",
      "Length of 9th row of zeroth pickle: 28\n",
      "Length of 10th row of zeroth pickle: 28\n",
      "Length of 11th row of zeroth pickle: 28\n",
      "Length of 12th row of zeroth pickle: 28\n",
      "Length of 13th row of zeroth pickle: 28\n",
      "Length of 14th row of zeroth pickle: 28\n",
      "Length of 15th row of zeroth pickle: 28\n",
      "Length of 16th row of zeroth pickle: 28\n",
      "Length of 17th row of zeroth pickle: 28\n",
      "Length of 18th row of zeroth pickle: 28\n",
      "Length of 19th row of zeroth pickle: 28\n",
      "Length of 20th row of zeroth pickle: 28\n",
      "Length of 21th row of zeroth pickle: 28\n",
      "Length of 22th row of zeroth pickle: 28\n",
      "Length of 23th row of zeroth pickle: 28\n",
      "Length of 24th row of zeroth pickle: 28\n",
      "Length of 25th row of zeroth pickle: 28\n",
      "Length of 26th row of zeroth pickle: 28\n",
      "Length of 27th row of zeroth pickle: 28\n",
      "No. of rows of zeroth element of pickle = 28\n"
     ]
    }
   ],
   "source": [
    "for i, k in enumerate(b):\n",
    "    if i <1:\n",
    "        count=0\n",
    "        for j in k:\n",
    "            print(\"Length of {}th row of zeroth pickle: {}\".format(count, len(j)))\n",
    "            count+=1\n",
    "    else:\n",
    "        print(\"No. of rows of zeroth element of pickle = {}\".format(count))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing that element as it is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFj1JREFUeJzt3XtwnXWdx/HPNydpStMWU3vDUiiXlrsUDSjIKngFVxdY\nlQVR0UHL7Cpe1tlZZHYWdtZdGVdE13Fxq6K4KtJRbqt4ZZnxBmhaGAotci3SUhooBVoqaXLy3T9y\nmKlM25xPck5O+uv7NdNpcvLJk99znpNvnz75Pt9EZgoAsPtra/UCAACNQUEHgEJQ0AGgEBR0ACgE\nBR0ACkFBB4BCUNABoBAUdAAoBAUdAArRPp5fbFJ05mR1jeeXxDiKSqWp289qtWnbjjbv3Ma+w5o7\nsjEGm7XpycycNVJuTAU9Ik6R9EVJFUlfy8xLd5WfrC69Kt4wli+JCayyd7f3CTlkxavPPGtuv/4i\n2jZ1mrfpbdu8fH+/lVeEl+cfjKL9Ir//SD25UV9yiYiKpC9LOlXS4ZLOjojDR7s9AMDYjOUa+nGS\nHsjMhzJzm6TvSTqtMcsCALjGUtDnSXp0u/fX1h77MxGxJCJ6I6J3QOZ/OwEAdWt6l0tmLs3Mnszs\n6VBns78cAOyxxlLQ10mav937+9YeAwC0wFgK+u8lLYyIAyJikqSzJN3YmGUBAFyjblvMzMGI+Iik\nn2q4bfHKzLynYSvD7qfdezlF115WfuM7vCaqzQfUn517u9fj/ux8b1/n/vZpKz905yorT5sjpDH2\noWfmTZJuatBaAABjwK3/AFAICjoAFIKCDgCFoKADQCEo6ABQCAo6ABRiXOeho8XazHnlQ15v9tOv\nP8jKb3rnc1b+5AV3WPn/mndb3dllZ+5tbburzZtL9LEDPmDlF21bZOWr9z5o5ZXNmy2P1uEMHQAK\nQUEHgEJQ0AGgEBR0ACgEBR0ACkFBB4BC0La4O2tyG2KecLSVX3/KgJU/Z+GdVv7Ts1da+S1Dz9ed\nPaPLe246wnvuO874mpU/f/r7rfyi8802RMbtFokzdAAoBAUdAApBQQeAQlDQAaAQFHQAKAQFHQAK\nQUEHgELQh46dyjazV/l5rzf7A923WvlqTrHye8WkurND8vqsqzlk5Y+atMnKd83aauV13FFWPFas\ntvI5OGjl0RqcoQNAISjoAFAICjoAFIKCDgCFoKADQCEo6ABQCAo6ABRiTH3oEbFG0mZJVUmDmdnT\niEWhPtHhHb7s92ZmbzpsLyv/wF992cpLXl+5qxL1n6+Yk+Vtm9Pr6f/a4m9Z+XPe/WErf/DvmtxX\nzrz1lmjEjUUnZ+aTDdgOAGAMuOQCAIUYa0FPSb+IiOURsaQRCwIAjM5YL7mcmJnrImK2pJ9HxL2Z\n+cvtA7VCv0SSJjf5mikA7MnGdIaemetqf/dJuk7ScTvILM3Mnszs6VDnWL4cAGAXRl3QI6IrIqa9\n8LakN0u6u1ELAwB4xnLJZY6k62K4Pald0ncz8ycNWRUAwDbqgp6ZD0k6uoFrQZvXDZ39/Vb+6fce\nb+Vnv/sRK/+bfu8/fK/qHLDyndFh5ZvJnYe+qKPLyq+NLVY+K14fd+XwRVa+uuo+K4/WoG0RAApB\nQQeAQlDQAaAQFHQAKAQFHQAKQUEHgEI0YtoiGiTavJGjZuecnujxWtu6zZGvB7Z7rXadMdXK96fX\n5uhwWyKHZLYJWmnp/7YusPL//uZlVv4rP3mnle9cZcUVFbMFd7DJ43z3EJyhA0AhKOgAUAgKOgAU\ngoIOAIWgoANAISjoAFAICjoAFII+9IkkvH9fK93dVj47vcb198/7rZXft93rK3dH0LaZ5x9bhuof\nL7x60FvLEZO8bx13X983/Ukrv7x/m5XfcKzXd7/fj6y4csjr00djcIYOAIWgoANAISjoAFAICjoA\nFIKCDgCFoKADQCEo6ABQCPrQmynM+eYDXi/xwJFHWPljj3zQyp81bZOVH8iqle8Ib2b2ukFv3vpH\nHq5/5vfkijdrfdHUPiv/6dkrrbz7XC42++Kf37/+Hn1J2nLmq6381GW3WXn3e0VJn/uOcIYOAIWg\noANAISjoAFAICjoAFIKCDgCFoKADQCEo6ABQiBGbVyPiSklvk9SXmUfWHpsh6RpJCyStkXRmZnpN\nyxNBk3tfKzO8eeWaO8uKP3vRs1b+ddPXWfmJ5nN9J1v56t/Uf7xWv+8Qa9vb/tLr+364+1Yrf0CH\nN1vedfmJ11j5TwycbeUPeehIK5+9d1t5tXn3MGjI6+vfXdVzhv5NSae86LELJd2cmQsl3Vx7HwDQ\nQiMW9Mz8paSnXvTwaZKuqr19laTTG7wuAIBptNfQ52Tm+trbj0ua06D1AABGacw/FM3MlLTTi5UR\nsSQieiOid0De/AgAQP1GW9A3RMQ+klT7e6eTijJzaWb2ZGZPhzpH+eUAACMZbUG/UdK5tbfPlXRD\nY5YDABitEQt6RFwt6VZJh0TE2og4T9Klkt4UEfdLemPtfQBAC43YTJuZO2tAfUOD11KcnDfbysea\nx6z8448cauX/6eh7rfzWIW8+e2d4vdnuzO8f3v4KK7+wr7fu7PSHF1jbfmzLdCs/2bzlodlOnLzB\nyndM937+tflAr49+av2HCrvAnaIAUAgKOgAUgoIOAIWgoANAISjoAFAICjoAFMLrMyuNOQ432r2n\nq63Pmyj82Hu8kaPXveVyK//wwICVb/YI1y9tWmDlO5/wRqa2v2xu3dlp199hbXvtQT1W/h+632bl\nz5i5wsq/Y6o3SnlmpcvKf+YV11v5z/7oHCtfmeWNjq4+8YSVb/ao7ImCM3QAKAQFHQAKQUEHgEJQ\n0AGgEBR0ACgEBR0ACkFBB4BC7Nl96M3W0WHF9z7dG5972CTv3+M27WXlqzlk5e8Z8MbtfumOk638\n/r/1tj+4dl394Tavx33+j717DFad4P3a3Uv39V4L1Zxi5SvhvXbmd2y08n2vHbTyez21wMp3/sjs\nQ99DcIYOAIWgoANAISjoAFAICjoAFIKCDgCFoKADQCEo6ABQiD27D92ckZyDXm/tkyfPt/L/cfAV\nVr4zvD53l9uHvrJ/npUf2uKtf9LG56y8M9G6ba/J1rZj0HtuBn71UivfdYx3rjVk7a00lFUrf1yn\nd6xmzH3Gyk952IorDlxg5auPen39ad5TMVFwhg4AhaCgA0AhKOgAUAgKOgAUgoIOAIWgoANAISjo\nAFCIEfvQI+JKSW+T1JeZR9Yeu0TShyS9MJT4osy8qVmLbJr0encrhxxs5dsGve1/Zb03H/y1B9xi\n5V3ufPNrHj/Wys+6zZtBnsvvsfLOjPOh57we98qGJ61859MzrPxrbl9i5Ved8G0rP2D2offngJVf\n/splVv6Yk//Oyu+z7H4rH5M7rXzJfejflHTKDh6/PDMX1/7sfsUcAAozYkHPzF9Kemoc1gIAGIOx\nXEO/ICLuiogrI6K7YSsCAIzKaAv6FZIOlLRY0npJl+0sGBFLIqI3InoH1D/KLwcAGMmoCnpmbsjM\namYOSfqqpON2kV2amT2Z2dMh7wcTAID6jaqgR8Q+2717hqS7G7McAMBo1dO2eLWkkyTNjIi1ki6W\ndFJELNbwhNI1ks5v4hoBAHUYsaBn5tk7ePjrTVjL2JnzzaPi9UEPzuiy8m3v67PyX9jvh1a+mntZ\n+Up4/yGbW/F6lQ+b/riVX/kX+1r552ecYOW7769/fv3jr/JeC9PWWHENdHmvzUuPvtbK37XteSt/\nWIc339ydvf/M0J+s/EFn3Wflt9w2x8rrLq9vfXfFnaIAUAgKOgAUgoIOAIWgoANAISjoAFAICjoA\nFGLEtsWWMtsQ7XG4c73WpydePsXKf2zBj6z8S9ua24bo6pD3/J834zdWfkqPN6L0D4d6x+vCeT+u\nO/vR+86ytn3sWx+x8kdNedTK79e+ycq/pK3+Fk1JatMkK++qmK+df5n/v1b+g4d8wsrPeHymlR9c\n95iVb3atqhdn6ABQCAo6ABSCgg4AhaCgA0AhKOgAUAgKOgAUgoIOAIWY0H3o7nhb17YDZlv5zSdt\ntfJHdHq9rJXweoOrOWTlXd0Vr+++2zxcF89a5X2Cma9m/c/n1Yd+29r2zIp3z8DW9Hru9zbvSdAE\n+21gHeG9GI6Y5I3nzfc8aeWH7p5u5aPP234OeMe3WThDB4BCUNABoBAUdAAoBAUdAApBQQeAQlDQ\nAaAQFHQAKMSE7kNXk+d9rzvJ6/W9/NgrrfzGapeVlwas9JC8mcpub7Db574l+6385PBefp3h9So7\nz89ss+fefe79vnLPQFabun33tdNsZ+3fa+Vv6nqdlW+f6n3vVjfRhw4AaCAKOgAUgoIOAIWgoANA\nISjoAFAICjoAFIKCDgCFGLEROCLmS/qWpDmSUtLSzPxiRMyQdI2kBZLWSDozMzeN+BUj6l6cO2O4\nfe4cK9/f7fVZn9D5lJV/zp5XPtVKu73BW4e853NI3vorqv/YSlI1vV7u2/q9XutXGiPCb/Na6PWy\nyp+s/KqBmVb+VZ0brfy0Nm+WvtvT796T0K7m9q3PbX/Gym88yrvPYO5j3veiNo1c+v6MUQclqd7b\nHuo5Qx+U9MnMPFzSqyV9OCIOl3ShpJszc6Gkm2vvAwBaZMSCnpnrM3NF7e3NklZLmifpNElX1WJX\nSTq9WYsEAIzMuoYeEQskHSPpdklzMnN97UOPa/iSDACgReou6BExVdIPJH08M5/d/mOZmdrJVZ6I\nWBIRvRHROyDzQiUAoG51FfSI6NBwMf9OZl5be3hDROxT+/g+kvp29LmZuTQzezKzp2OC/SJbACjJ\niAU9IkLS1yWtzszPb/ehGyWdW3v7XEk3NH55AIB61TO/9DWS3itpZUTcWXvsIkmXSloWEedJekTS\nmXV9RaNVrW2K12r02DsPsvJHvPIhK99mthrtW/Fan5o9rnbxzy6w8h0bvNa2N77xDit/80+PsfLT\nHrHi6u+u/3h1bvJaKDce7406bp88aOVn/MQbt/vUEVZc5556i5Vf0r3cyj9vtqTu1+59r7xrqtfW\nefN5d1n5tbfvZ+VlvjabNRp8xIKemb+Wdtpg/IbGLgcAMFrcKQoAhaCgA0AhKOgAUAgKOgAUgoIO\nAIWgoANAIerpQ2+cCEVH/WM+h15+sLX5rXO83tfXz7zXyu/d5vUGu+Nqp5gjUE/83XlWfu4vvMP9\nknuetvIPfup5K3/Q9HusvCaZI1+frL9XuTJntrXtWf/z7Mih7S1aYMXbNu7wxuudmrHMG+18VZxs\n5e86YZ6Vf8+cW638fu1brfxQvfNkaw6e4j2fKz7t7e/Mt1txyR6tXR/O0AGgEBR0ACgEBR0ACkFB\nB4BCUNABoBAUdAAoBAUdAAoxrn3oUWlT2/T65x5vm+wtr3rQn6z8B/f2+tCr6fWJu33l92zz1v/c\nH6db+Vl93gxv3e8OefZUtzznfYLZu+vc81Dte8Jbi+su77U21Fbxtj9UteILL3vQyvdO8e4J+czb\n3d93481D7wjv+XnL1Lut/H9vfK2VH/j7E6z8y77Ua+VV5y0tnKEDQCEo6ABQCAo6ABSCgg4AhaCg\nA0AhKOgAUAgKOgAUYnznoVcqUvfedcefWDzZ2vynjrnWyk9t87bfn14f933bvPngH7n/bCvf9aj3\n7/HklY9a+epWb0a1Iry82TvtygFvHn1Tuc+N23Pfbt6zscGbD77vzxdY+TWn1v99LklPD3n3YCye\n5O3vwR3e/PR/Pf56K//PT7/LyjfrtckZOgAUgoIOAIWgoANAISjoAFAICjoAFIKCDgCFoKADQCFG\nbOaMiPmSviVpjqSUtDQzvxgRl0j6kKQXBklflJk37Wpb2V7R4Kz6Z3jvf8ZDdWcl6expf7Tykjev\nfPU2rzd4SpvX+7p2xcus/KLvr7XyWW1u37fS2989SpOfm2Yf22krHrPyn7r3r638NUd+w8qvq3p9\n3Pu1e/PWz5m20cpfPGjFFcce5X3C775fV6ye7vxBSZ/MzBURMU3S8oj4ee1jl2fm57yVAQCaYcSC\nnpnrJa2vvb05IlZLmtfshQEAPNY19IhYIOkYSbfXHrogIu6KiCsjonsnn7MkInojondgwPyVYwCA\nutVd0CNiqqQfSPp4Zj4r6QpJB0parOEz+Mt29HmZuTQzezKzp6OjqwFLBgDsSF0FPSI6NFzMv5OZ\n10pSZm7IzGpmDkn6qqTjmrdMAMBIRizoERGSvi5pdWZ+frvH99kudoYk79dqAwAaqp4ul9dIeq+k\nlRFxZ+2xiySdHRGLNdzKuEbS+Y1e3L23HmDlX977USufs/ut/AWvuMXK/+ctb7Hyh12xzsoP/tHL\nA6NVnemNw530Da9NcMnfeqOjj53xiJX/3q+Ot/ILj/C+t16y2huP3PaA13Jcr3q6XH4taUer3WXP\nOQBgfHGnKAAUgoIOAIWgoANAISjoAFAICjoAFIKCDgCFqKcPvXG2Pq+23tV1xxdu8MbJ5l6dVn7o\ngTVW/mdTvL74QwZXWfnBLVusvI3xtuVq8rGNB7zR1Hv3TbPy1RuetPJ3HnyIlT90/b1WPge8ebiV\nd8y38mrz+tbr3mxTtgoAGHcUdAAoBAUdAApBQQeAQlDQAaAQFHQAKAQFHQAKETmOvckR8YSkHQ0y\nninJa0TdvbG/5dqT9lVif8fL/pk5a6TQuBb0nS4iojcze1q9jvHC/pZrT9pXif2daLjkAgCFoKAD\nQCEmSkFf2uoFjDP2t1x70r5K7O+EMiGuoQMAxm6inKEDAMaopQU9Ik6JiD9ExAMRcWEr1zIeImJN\nRKyMiDsjorfV62m0iLgyIvoi4u7tHpsRET+PiPtrf3e3co2NtJP9vSQi1tWO8Z0R8dZWrrFRImJ+\nRNwSEasi4p6I+Fjt8SKP7y72d0If35ZdcomIiqT7JL1J0lpJv5d0dmZ6Q8R3IxGxRlJPZhbZtxsR\nr5W0RdK3MvPI2mOflfRUZl5a+0e7OzP/sZXrbJSd7O8lkrZk5udaubZGi4h9JO2TmSsiYpqk5ZJO\nl/R+FXh8d7G/Z2oCH99WnqEfJ+mBzHwoM7dJ+p6k01q4HoxRZv5S0lMvevg0SVfV3r5Kw98URdjJ\n/hYpM9dn5ora25slrZY0T4Ue313s74TWyoI+T9Kj272/VrvBEzZGKekXEbE8Ipa0ejHjZE5mrq+9\n/bikOa1czDi5ICLuql2SKeISxPYiYoGkYyTdrj3g+L5of6UJfHz5oej4OjEzF0s6VdKHa/9l32Pk\n8PW90tuqrpB0oKTFktZLuqy1y2msiJgq6QeSPp6Zz27/sRKP7w72d0If31YW9HWStv9FfPvWHitW\nZq6r/d0n6ToNX3Yq3Yba9cgXrkv2tXg9TZWZGzKzmplDkr6qgo5xRHRouLh9JzOvrT1c7PHd0f5O\n9OPbyoL+e0kLI+KAiJgk6SxJN7ZwPU0VEV21H64oIrokvVnS3bv+rCLcKOnc2tvnSrqhhWtpuheK\nW80ZKuQYR0RI+rqk1Zn5+e0+VOTx3dn+TvTj29Ibi2otP1+QVJF0ZWb+W8sW02QRcaCGz8olqV3S\nd0vb34i4WtJJGp5It0HSxZKul7RM0n4anrR5ZmYW8YPEnezvSRr+73hKWiPp/O2uMe+2IuJESb+S\ntFLSUO3hizR8Xbm447uL/T1bE/j4cqcoABSCH4oCQCEo6ABQCAo6ABSCgg4AhaCgA0AhKOgAUAgK\nOgAUgoIOAIX4f3Rd/JHBZDJOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d2f3550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(b[0],aspect=\"auto\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the balance across the data\n",
    "\n",
    "- The shape of each pickle is almost alike which will help to maintain the balance between the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1872, 28, 28)\n",
      "(1873, 28, 28)\n",
      "(1873, 28, 28)\n",
      "(1873, 28, 28)\n",
      "(1873, 28, 28)\n",
      "(1872, 28, 28)\n",
      "(1872, 28, 28)\n",
      "(1872, 28, 28)\n",
      "(1872, 28, 28)\n",
      "(1872, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "file_name = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"]\n",
    "for name in file_name:\n",
    "    with open('/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/{}.pickle'.format(name), 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and pruning the data as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/A.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/B.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/C.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/D.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/E.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/F.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/G.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/H.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/I.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large/J.pickle']\n",
      "['/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/A.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/B.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/C.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/D.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/E.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/F.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/G.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/H.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/I.pickle', '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small/J.pickle']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "mypath_train = '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_large'\n",
    "mypath_test = '/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST_small'\n",
    "onlyfiles_train = [join(mypath_train, f) for f in listdir(mypath_train) if isfile(join(mypath_train, f))]\n",
    "onlyfiles_test = [join(mypath_test, f) for f in listdir(mypath_test) if isfile(join(mypath_test, f))]\n",
    "onlyfiles_train = onlyfiles_train[1:]\n",
    "onlyfiles_test = onlyfiles_test[1:]\n",
    "print(onlyfiles_train)\n",
    "print(onlyfiles_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (200000, 28, 28) (200000,)\n",
      "Validation: (10000, 28, 28) (10000,)\n",
      "Testing: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def make_arrays(nb_rows, img_size):\n",
    "    if nb_rows:\n",
    "        dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "        labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "    else:\n",
    "        dataset, labels = None, None\n",
    "    return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "    num_classes = len(pickle_files)\n",
    "    valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "    train_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "    vsize_per_class = valid_size // num_classes\n",
    "    tsize_per_class = train_size // num_classes\n",
    "    \n",
    "    start_v, start_t = 0, 0\n",
    "    end_v, end_t = vsize_per_class, tsize_per_class\n",
    "    end_l = vsize_per_class+tsize_per_class\n",
    "    for label, pickle_file in enumerate(pickle_files):\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                letter_set = pickle.load(f)\n",
    "                # let's shuffle the letters to have random validation and training set\n",
    "                np.random.shuffle(letter_set)\n",
    "            if valid_dataset is not None:\n",
    "                valid_letter = letter_set[:vsize_per_class, :, :]\n",
    "                valid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "                valid_labels[start_v:end_v] = label\n",
    "                start_v += vsize_per_class\n",
    "                end_v += vsize_per_class\n",
    "                    \n",
    "            train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
    "            train_dataset[start_t:end_t, :, :] = train_letter\n",
    "            train_labels[start_t:end_t] = label\n",
    "            start_t += tsize_per_class\n",
    "            end_t += tsize_per_class\n",
    "        except Exception as e:\n",
    "            print('Unable to process data from', pickle_file, ':', e)\n",
    "            raise\n",
    "    return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "            \n",
    "            \n",
    "train_size = 200000\n",
    "valid_size = 10000\n",
    "test_size = 10000\n",
    "\n",
    "\n",
    "train_datasets = onlyfiles_train\n",
    "test_datasets = onlyfiles_test\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "  train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomize the trianing data to avoid crossing validation set and training set to be well distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the dataset just generated\n",
    "\n",
    "- Each row of `train_dataset` is the normalized pixel values of an image same as the above pickle\n",
    "- Each label is mapped to a number from `0 to 10` to letters `A to J` respectively. That number is given in `train_labels`. The row numbers of `train_dataset` and `train_labels`\n",
    "- Same is applicable for `test_dataset`, `test_labels` and `valid_dataset` , `valid_labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 28, 28)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.49607843,\n",
       "        -0.5       , -0.39019608,  0.43725491,  0.5       ,  0.49607843,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.49215686,  0.5       ,  0.5       ,\n",
       "         0.49215686,  0.5       ,  0.20196079],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.49607843,\n",
       "        -0.5       , -0.43333334, -0.24901961, -0.20980392, -0.06862745,\n",
       "         0.34705883,  0.5       ,  0.49607843,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.49215686,  0.5       ,  0.35882354,  0.00588235,\n",
       "        -0.17450981, -0.21372549, -0.38627452],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.48431373, -0.5       ,\n",
       "         0.01764706,  0.5       ,  0.48823529,  0.5       ,  0.5       ,\n",
       "         0.49215686,  0.5       ,  0.17450981, -0.46078432, -0.5       ,\n",
       "        -0.49607843, -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.48823529, -0.48039216, -0.5       ,\n",
       "         0.18235295,  0.5       ,  0.48823529,  0.5       ,  0.49215686,\n",
       "         0.5       ,  0.32745099, -0.44509804, -0.5       , -0.48431373,\n",
       "        -0.48823529, -0.48823529, -0.49607843],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.49215686, -0.5       , -0.38235295,\n",
       "         0.42941177,  0.5       ,  0.49607843,  0.5       ,  0.49215686,\n",
       "         0.5       , -0.13921569, -0.5       , -0.48431373, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.48823529, -0.5       , -0.05686275,\n",
       "         0.5       ,  0.48823529,  0.5       ,  0.49215686,  0.5       ,\n",
       "         0.35490197, -0.46862745, -0.5       , -0.49607843, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.49607843, -0.5       , -0.48039216,  0.31176472,\n",
       "         0.5       ,  0.49215686,  0.5       ,  0.48431373,  0.5       ,\n",
       "        -0.01764706, -0.5       , -0.48823529, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.48823529, -0.5       , -0.21372549,  0.5       ,\n",
       "         0.49215686,  0.5       ,  0.49607843,  0.5       ,  0.43725491,\n",
       "        -0.34705883, -0.5       , -0.49215686, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.49215686, -0.5       ,  0.17450981,  0.5       ,\n",
       "         0.48823529,  0.5       ,  0.48823529,  0.5       ,  0.14705883,\n",
       "        -0.5       , -0.48823529, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49215686, -0.5       , -0.33137256,  0.44901961,  0.5       ,\n",
       "         0.49607843,  0.5       ,  0.49215686,  0.5       , -0.24117647,\n",
       "        -0.5       , -0.48823529, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.48823529, -0.5       ,  0.01372549,  0.5       ,  0.48431373,\n",
       "         0.5       ,  0.48823529,  0.5       ,  0.28039217, -0.48823529,\n",
       "        -0.5       , -0.49607843, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.49607843,\n",
       "        -0.5       , -0.45686275,  0.37843138,  0.5       ,  0.49215686,\n",
       "         0.5       ,  0.49215686,  0.5       , -0.08039216, -0.5       ,\n",
       "        -0.48823529, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.48431373,\n",
       "        -0.5       , -0.13529412,  0.5       ,  0.49215686,  0.5       ,\n",
       "         0.49607843,  0.5       ,  0.40588236, -0.41764706, -0.5       ,\n",
       "        -0.49607843, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       ,  0.23333333,  0.5       ,  0.48823529,  0.5       ,\n",
       "         0.48431373,  0.5       ,  0.07254902, -0.5       , -0.48823529,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.49215686, -0.5       ,\n",
       "        -0.28039217,  0.49215686,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.48823529, -0.30392158, -0.5       , -0.49215686,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.48823529, -0.5       ,\n",
       "         0.09215686,  0.5       ,  0.48431373,  0.5       ,  0.48823529,\n",
       "         0.5       ,  0.21372549, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.49607843, -0.5       , -0.40588236,\n",
       "         0.42156863,  0.5       ,  0.49607843,  0.5       ,  0.49215686,\n",
       "         0.5       , -0.15490197, -0.5       , -0.48823529, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.48823529, -0.5       , -0.06078431,\n",
       "         0.5       ,  0.49215686,  0.5       ,  0.49215686,  0.5       ,\n",
       "         0.36274511, -0.46470588, -0.5       , -0.49607843, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.49607843, -0.5       , -0.47647059,  0.29607844,\n",
       "         0.5       ,  0.49215686,  0.5       ,  0.48431373,  0.5       ,\n",
       "        -0.00980392, -0.5       , -0.48823529, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.48823529, -0.5       , -0.22156863,  0.5       ,\n",
       "         0.49215686,  0.5       ,  0.49607843,  0.5       ,  0.43725491,\n",
       "        -0.34705883, -0.5       , -0.49215686, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.48823529, -0.5       ,  0.17058824,  0.5       ,\n",
       "         0.48823529,  0.5       ,  0.48823529,  0.5       ,  0.15490197,\n",
       "        -0.5       , -0.49215686, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49215686, -0.5       , -0.33137256,  0.44901961,  0.5       ,\n",
       "         0.49607843,  0.5       ,  0.49215686,  0.5       , -0.23333333,\n",
       "        -0.5       , -0.48823529, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.48823529, -0.5       ,  0.00588235,  0.5       ,  0.48823529,\n",
       "         0.5       ,  0.48823529,  0.5       ,  0.29607844, -0.49215686,\n",
       "        -0.5       , -0.49607843, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.49607843,\n",
       "        -0.5       , -0.43333334,  0.38235295,  0.5       ,  0.49215686,\n",
       "         0.5       ,  0.48823529,  0.5       , -0.07647059, -0.5       ,\n",
       "        -0.48823529, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.48823529, -0.48823529, -0.48823529, -0.47647059,\n",
       "        -0.5       , -0.02941176,  0.5       ,  0.48823529,  0.5       ,\n",
       "         0.49607843,  0.5       ,  0.44901961, -0.36666667, -0.5       ,\n",
       "        -0.48039216, -0.49215686, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.49215686, -0.5       ,\n",
       "        -0.25686276,  0.46078432,  0.5       ,  0.49607843,  0.5       ,\n",
       "         0.48823529,  0.5       ,  0.26078433, -0.49607843, -0.5       ,\n",
       "        -0.49607843, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.48431373, -0.28039217, -0.2372549 , -0.19019608,  0.06862745,\n",
       "         0.44509804,  0.5       ,  0.49607843,  0.5       ,  0.5       ,\n",
       "         0.49607843,  0.5       ,  0.45294118,  0.04509804, -0.18627451,\n",
       "        -0.22156863, -0.33529413, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.19411765,  0.49607843,  0.5       ,  0.49607843,  0.5       ,\n",
       "         0.49215686,  0.49607843,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.48823529,\n",
       "         0.5       , -0.01764706, -0.5       , -0.48823529, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncN1X6G65WwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e1842e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[0],aspect=\"auto\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the final data as a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = '/Users/jenkins/sleeba/deep_learning_udacity'\n",
    "\n",
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 690800506\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the final pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/jenkins/sleeba/deep_learning_udacity/not_mnist/notMNIST.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEfdJREFUeJzt3X2MXOV1x/Hf2d3xGtvINTVsLeNgm5gIioJRtm5TUEND\nk5gWYiitiyOIUVGMqhQVlD+KrFbQP4JQG0yQigBTLOxg3iTz4lYoKdAoLuJFrBHBTlxeSkzBLDbU\nETZ1WO/L6R97qbZod2fOzNyd2ePvR7I8c+fsM8/du/vz9d1znzV3FwBg+uto9QQAAM1BoANAEgQ6\nACRBoANAEgQ6ACRBoANAEgQ6ACRBoANAEgQ6ACTRNZVvNsO6faZmT+Vboo1Zd3eo/uTT/jtUf5zV\nfr7iit0xbbJQPSbXbp//sufz2sdzQ/WHXzvwgbufWK2uoUA3s5WSbpPUKemf3P3myepnarZ+285v\n5C0xlSz4TRNcRqJz8amh+lv+5Qeh+tNnzKq5dthHQmN3Bv6xQHWDPhyqr1hnSTMZVfZ8vrbnwlD9\nU1/+/lu11NX9VWlmnZJul3SBpDMkrTGzM+odDwDQmEZOM1ZIesPd33T3o5IelLSqOdMCAEQ1EugL\nJb095vk7xbb/x8zWmVmfmfUNaqCBtwMATKb0C4HuvtHde929t6LYD8EAALVrJND3SVo05vnJxTYA\nQAs0EugvSlpmZkvMbIakyyRtb860AABRdbctuvuQmf2lpB9ptG1xk7v/rGkzQ3p26KNQ/brrrgvV\nD86qve3yw1Nj5zbXrXksVL9u7ruh+uneRll229+WQ/ND9X/3wz8J1c/bHWvZrRyJtezO2/lBqL5W\nDfWhu/sTkp5o0lwAAA1or3/WAQB1I9ABIAkCHQCSINABIAkCHQCSINABIIkpXQ8d00xwOdyooff2\nh+pnPRqrt8qMmmvnDh4NjX3ziReF6tddeleofkixPu7Oks/Nyu4rP+eVPw7Vz10d6+P+7KHnQ/Vl\nLx0d+2zWjjN0AEiCQAeAJAh0AEiCQAeAJAh0AEiCQAeAJGhbxLRhXcEv145g61nAyacdKG3sqVB2\nG+KGg0tD9XMv/zBUP3zoUKg+0sIqSQouXxzlw8HGxRq7IjlDB4AkCHQASIJAB4AkCHQASIJAB4Ak\nCHQASIJAB4Ak6EPHtOEjweV8hwZqLu08fVlo6H/83A9ic9HMUHWXYn3f7WbLXStD9T0fPBuqj/aV\ne3B55OmKM3QASIJAB4AkCHQASIJAB4AkCHQASIJAB4AkCHQASKKhPnQz2yvpsKRhSUPu3tuMSQHj\nseD65pElrd+87MTQ2J+fEesrH/DBUH23VUL1Za9vfu+hk0L1Czb9NFQfXX3ch2Kfz2NFM24s+n13\n/6AJ4wAAGsAlFwBIotFAd0lPmdlOM1vXjAkBAOrT6CWXc919n5mdJOlJM/sPd98xtqAI+nWSNFOz\nGnw7AMBEGjpDd/d9xd8HJD0qacU4NRvdvdfdeyvqbuTtAACTqDvQzWy2mR3/yWNJX5W0u1kTAwDE\nNHLJpUfSo2b2yTj3u/sPmzIrAEBY3YHu7m9KOquJc8GxxoJ95UNDseG7a7/Ed/kl/xYaO6qj5Iay\nsvvQv7v90lD90v95LlRvXbEoin4tHCtoWwSAJAh0AEiCQAeAJAh0AEiCQAeAJAh0AEiiGastAnWx\nzljrXLRV7cNLz6659m/m3xkau+w2weHI2r+SZnXMCNXvOXokVH/qw4dD9R6qlnwk+hEYD2foAJAE\ngQ4ASRDoAJAEgQ4ASRDoAJAEgQ4ASRDoAJAEfehombJ7jzu+eaC0sUcU6xOXYn3oQ4r1uXcGz82+\n8dM/D9Wf1Bf73TUsh9sanKEDQBIEOgAkQaADQBIEOgAkQaADQBIEOgAkQaADQBL0oaN5OmK91hqJ\n9Vr7F88K1d93+u2B6jmhsbuCfeVRHSWfa83eMrfU8dEanKEDQBIEOgAkQaADQBIEOgAkQaADQBIE\nOgAkQaADQBJV+9DNbJOkCyUdcPczi20nSHpI0mJJeyWtdvdfljdNTAfWYaF6Dy4p/saamaH6JZXa\ne8uPjBwNjT2rY0aofsAHQ/XdVgnVX9vfG6qf8/jOUH105Xofjt1jgOao5Qz9XkkrP7XteklPu/sy\nSU8XzwEALVQ10N19h6SDn9q8StLm4vFmSRc3eV4AgKB6r6H3uHt/8fg9ST1Nmg8AoE4N/1DU3V2T\nXGIzs3Vm1mdmfYMaaPTtAAATqDfQ95vZAkkq/p7wt/G6+0Z373X33oq663w7AEA19Qb6dklri8dr\nJT3enOkAAOpVNdDN7AFJz0n6nJm9Y2ZXSbpZ0lfM7HVJf1A8BwC0UNU+dHdfM8FL5zd5Lmg3Fuwr\nHxoK1Xf+WmxN7g0XbA3VR1Rseq9v/q+PrAjVLxp6NlRvXbFfnRD9WkBzcKcoACRBoANAEgQ6ACRB\noANAEgQ6ACRBoANAErFeJBxTrCu2hKsPxpagffebvxmqv3j2T0L1g177Eq7RtsXh4Nq/0fF3fBwq\n15It/xWqjzYVshzu9MAZOgAkQaADQBIEOgAkQaADQBIEOgAkQaADQBIEOgAkQR86JhTtK486bfWr\npY4/okiveKxPfMBjndyzbEao/sodV4Xql729M1TPcrg5cYYOAEkQ6ACQBIEOAEkQ6ACQBIEOAEkQ\n6ACQBIEOAEnQh34s6Yj1Wmsktgb20ZW/FarfuuTOUH20V7zbYuu5R8zqiPWVD/hgqH7pZg/VR/lI\nueOjNThDB4AkCHQASIJAB4AkCHQASIJAB4AkCHQASIJAB4Akqvahm9kmSRdKOuDuZxbbbpT0LUnv\nF2Xr3f2JsiaJ5rAOC9V7ZDlxSW9fEVszu2KxvvIjI7H12SO94tE+8WiP+6Wvfz1U3/njl0L1YcF7\nDDA91HKGfq+kleNsv9Xdlxd/CHMAaLGqge7uOyQdnIK5AAAa0Mg19GvM7BUz22Rm85o2IwBAXeoN\n9DskLZW0XFK/pFsmKjSzdWbWZ2Z9gxqo8+0AANXUFejuvt/dh919RNLdklZMUrvR3Xvdvbei7nrn\nCQCooq5AN7MFY55eIml3c6YDAKhXLW2LD0g6T9J8M3tH0g2SzjOz5ZJc0l5JV5c4RwBADaoGuruv\nGWfzPSXMBVEW7CsfivWJdy05JVT/0O/eFaqXYmuKd1t5y/d3lHyP3bsPLQ7Vn6j+UL11xT430a8F\nTA/cKQoASRDoAJAEgQ4ASRDoAJAEgQ4ASRDoAJBEeX1gKJ11xpafjbaqvbl2Yaj+C92xNsRBjy3h\nGl1uNzJ+dOyth389VN9zX+zeu+DKxfJhlsMFZ+gAkAaBDgBJEOgAkASBDgBJEOgAkASBDgBJEOgA\nkAR96O2k5OVwO2bODNVfsuqZUH27KbMP/YZ//tNQ/amHnw/Vsxwu6sEZOgAkQaADQBIEOgAkQaAD\nQBIEOgAkQaADQBIEOgAkQR96Gyl7ffMPL14eqr+p585Qfdnrmw97bJXwWR21r8++5+iR0NifffCj\nUL2HqiUfiX4EwBk6AKRBoANAEgQ6ACRBoANAEgQ6ACRBoANAEgQ6ACRRtQ/dzBZJ2iKpR6PttBvd\n/TYzO0HSQ5IWS9orabW7/7K8qaJRvvb9UscfUaxPXIr1oQ8p1ufeGThfuXzXlaGx5/ftDtWrI7av\nGontKyDVdoY+JOk77n6GpN+R9G0zO0PS9ZKedvdlkp4ungMAWqRqoLt7v7u/VDw+LGmPpIWSVkna\nXJRtlnRxWZMEAFQXuoZuZoslnS3pBUk97t5fvPSeRi/JAABapOZAN7M5krZJutbdD419zd1dEyxX\nYWbrzKzPzPoGNdDQZAEAE6sp0M2sotEw3+rujxSb95vZguL1BZIOjPex7r7R3Xvdvbei7mbMGQAw\njqqBbmYm6R5Je9x9w5iXtktaWzxeK+nx5k8PAFCrWpbPPUfSFZJ2mdnLxbb1km6W9LCZXSXpLUmr\ny5niNBZsVYsuh+tfPCtUf/8Zt4fqpTmh6q5gG2JUR4m3TczcMq+0sSXJOixUH1wpGJBUQ6C7+zOS\nJvpqPL+50wEA1Is7RQEgCQIdAJIg0AEgCQIdAJIg0AEgCQIdAJKopQ8ddSq79/g//+y4UP2SSqyv\nfMAHQ/XdVmmr8dfv/3zNtXO29YXGjvJhlsNF+ThDB4AkCHQASIJAB4AkCHQASIJAB4AkCHQASIJA\nB4Ak6EOPsGBfeXB9867fiP1a1lv/aEuoPqrM9cenwmPbzq25dtHIs6GxrSv2rRP9WgDqMb2/YwEA\n/4dAB4AkCHQASIJAB4AkCHQASIJAB4AkCHQASKKt+9Cjvb5li85n5OOPQ/WvX7s0VP/12T8K1Ze9\n/vhwcEH36Pi/GPwoVH/K9oM11waXopc6O2P1Ix6sZ/10xHGGDgBJEOgAkASBDgBJEOgAkASBDgBJ\nEOgAkASBDgBJVG2sNrNFkrZI6pHkkja6+21mdqOkb0l6vyhd7+5PNHNypa8h3RHrJfZgX/mvVq0I\n1f/kG/8QqpfmhKq7FOydDhpSrHe6M3g+cdN7XwvVj+x6NVQf4UePBj8g2IcO1KGWO2WGJH3H3V8y\ns+Ml7TSzJ4vXbnX375U3PQBAraoGurv3S+ovHh82sz2SFpY9MQBATOj/vGa2WNLZkl4oNl1jZq+Y\n2SYzmzfBx6wzsz4z6xvUQEOTBQBMrOZAN7M5krZJutbdD0m6Q9JSScs1egZ/y3gf5+4b3b3X3Xsr\n6m7ClAEA46kp0M2sotEw3+ruj0iSu+9392F3H5F0t6TYTwABAE1VNdDNzCTdI2mPu28Ys33BmLJL\nJO1u/vQAALWqpcvlHElXSNplZi8X29ZLWmNmyzXayrhX0tVVRzKTVWbUPLmB88+quVaSBufE2uCO\nBuvf/1KsVe2pL2+oXjTGgq5YG2J0udpOK/e2g7LbIv92QWy54C/deV3NtfOfjy2NXPlVrA3x+L1H\nQvV6/pVYPaDaulyekWTjvNTUnnMAQGO4UxQAkiDQASAJAh0AkiDQASAJAh0AkiDQASCJWPNtg4ZP\nmKWDF32h5vrnbro9NH60z7rsPu5BPy5U32595VFlz+czwT79X1x0d821AxcOhsbutkqoftl9fxGq\nX/p8qFzWFftWLn1parREeyUCAKBuBDoAJEGgA0ASBDoAJEGgA0ASBDoAJEGgA0AS5h5b17mhNzN7\nX9Jb47w0X9IHUzaR1mN/8zqW9lVif6fKKe5+YrWiKQ30CSdh1ufuva2ex1Rhf/M6lvZVYn/bDZdc\nACAJAh0AkmiXQN/Y6glMMfY3r2NpXyX2t620xTV0AEDj2uUMHQDQoJYGupmtNLNXzewNM7u+lXOZ\nCma218x2mdnLZtbX6vk0m5ltMrMDZrZ7zLYTzOxJM3u9+HteK+fYTBPs741mtq84xi+b2R+2co7N\nYmaLzOzHZvZzM/uZmf1VsT3l8Z1kf9v6+LbskouZdUp6TdJXJL0j6UVJa9z95y2Z0BQws72Set09\nZd+umf2epI8kbXH3M4ttfy/poLvfXPyjPc/d/7qV82yWCfb3Rkkfufv3Wjm3ZjOzBZIWuPtLZna8\npJ2SLpZ0pRIe30n2d7Xa+Pi28gx9haQ33P1Ndz8q6UFJq1o4HzTI3XdIOvipzaskbS4eb9boN0UK\nE+xvSu7e7+4vFY8PS9ojaaGSHt9J9rettTLQF0p6e8zzdzQNPmENcklPmdlOM1vX6slMkR537y8e\nvyepp5WTmSLXmNkrxSWZFJcgxjKzxZLOlvSCjoHj+6n9ldr4+PJD0al1rrsvl3SBpG8X/2U/Zvjo\n9b3sbVV3SFoqabmkfkm3tHY6zWVmcyRtk3Stux8a+1rG4zvO/rb18W1loO+TtGjM85OLbWm5+77i\n7wOSHtXoZafs9hfXIz+5LnmgxfMplbvvd/dhdx+RdLcSHWMzq2g03La6+yPF5rTHd7z9bffj28pA\nf1HSMjNbYmYzJF0maXsL51MqM5td/HBFZjZb0lcl7Z78o1LYLmlt8XitpMdbOJfSfRJuhUuU5Bib\nmUm6R9Ied98w5qWUx3ei/W3349vSG4uKlp/vS+qUtMndv9uyyZTMzJZq9Kxckrok3Z9tf83sAUnn\naXRFuv2SbpD0mKSHJX1Goyttrnb3FD9InGB/z9Pof8dd0l5JV4+5xjxtmdm5kv5d0i5JI8Xm9Rq9\nrpzu+E6yv2vUxseXO0UBIAl+KAoASRDoAJAEgQ4ASRDoAJAEgQ4ASRDoAJAEgQ4ASRDoAJDE/wL5\ncN1X6G65WwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116f9fcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(b[\"train_dataset\"][0])\n",
    "print(b[\"train_labels\"][0])\n",
    "plt.imshow(b[\"train_dataset\"][0],aspect=\"auto\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the overlap in the different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(b[\"train_dataset\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking common elements in `train_dataset` and `test_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['train_dataset'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since the dataset is too big, randomly selecting 1000 images and looking for overlapping in examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_train = b['train_dataset'][np.random.randint(b['train_dataset'].shape[0], size=1000), :]\n",
    "sample_test = b['test_dataset'][np.random.randint(b['test_dataset'].shape[0], size=1000), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for el in sample_train:\n",
    "    for el2 in sample_test:\n",
    "        if (el==el2).all():\n",
    "            count+=1\n",
    "            break\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Here there is 10 samples with are exactly identical in training and testing datasets. This can be good or bad according to the application. If the letters are recurring in in your test case, then we don't need to remove the duplicates.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_train = b['train_dataset'][np.random.randint(b['train_dataset'].shape[0], size=1000), :]\n",
    "sample_test = b['test_dataset'][np.random.randint(b['test_dataset'].shape[0], size=1000), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for el in sample_train:\n",
    "    for el2 in sample_test:\n",
    "        if np.allclose(el,el2):\n",
    "            count+=1\n",
    "            break\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Here there is 5 samples with are almost identical in training and testing datasets. This can be good or bad according to the application. If the letters are recurring in in your test case, then we don't need to remove the duplicates.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training a sample data set of 5000 using Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(np.arange(len(b['train_dataset'])), 5000, replace=False)\n",
    "x_sample = b['train_dataset'][idx]\n",
    "y_sample = b['train_labels'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.36666667,  0.26078433,  0.47647059,\n",
       "        0.49607843,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "        0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "        0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "        0.49607843,  0.44509804,  0.19411765], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = x_sample.reshape((len(x_sample), -1))\n",
    "label = y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.25, random_state=10)\n",
    "model = LogisticRegression(verbose=10, n_jobs=-1, max_iter=200, )\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792\n"
     ]
    }
   ],
   "source": [
    "print (metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Accuracy of the model is 79.2 % considering the random 5000 samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
